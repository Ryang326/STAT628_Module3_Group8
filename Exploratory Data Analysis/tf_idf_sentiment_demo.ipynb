{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aminoacid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aminoacid/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aminoacid/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/aminoacid/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PizzaReview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17942"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Select top10 Chain Pizza Restaurants\n",
    "shop_list=[\"Domino\",\"Pizza hut\",\"Little caesars\",\"Papa John\",\"California pizza kitchen\",\n",
    "           \"Papa Murphy\",\"Sbarro\",\"Marco's pizza\",\"Chuck E. cheese\",\"Cici's pizza\"]\n",
    "tem1 = pd.DataFrame(columns=['business_id','name','city','state','stars_x','review_count',\n",
    "                             'attributes','user_id','stars_y','text','date'])\n",
    "\n",
    "for a in shop_list:\n",
    "    tem = df[df['name'].str.contains(a, na=False, case=False)==True]\n",
    "    tem['name']=a\n",
    "    tem1 = pd.concat([tem1,tem],axis = 0)\n",
    "   \n",
    "PizzaChain = tem1.copy()\n",
    "PizzaChain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Pizza hut\"\n",
    "df1 = PizzaChain[PizzaChain['name'] == \"Pizza hut\"]\n",
    "#restName = df1.business_id.unique()\n",
    "#restName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>shop_star</th>\n",
       "      <th>state</th>\n",
       "      <th>text</th>\n",
       "      <th>user_star</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>So now for an update.\\n\\nI've ordered 3x from ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>I came here for an interview, I found out that...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>I know it's Pizza Hut, but even with my expect...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>Lunch time they have the $3.99 personal pan pi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>This weekend I ordered delivery for the first ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  shop_star state  \\\n",
       "2378  kqhHw_9KA30_RYk66mMbJA        1.0    BC   \n",
       "2379  kqhHw_9KA30_RYk66mMbJA        1.0    BC   \n",
       "2380  kqhHw_9KA30_RYk66mMbJA        1.0    BC   \n",
       "2381  kqhHw_9KA30_RYk66mMbJA        1.0    BC   \n",
       "2382  kqhHw_9KA30_RYk66mMbJA        1.0    BC   \n",
       "\n",
       "                                                   text  user_star  \\\n",
       "2378  So now for an update.\\n\\nI've ordered 3x from ...        1.0   \n",
       "2379  I came here for an interview, I found out that...        1.0   \n",
       "2380  I know it's Pizza Hut, but even with my expect...        1.0   \n",
       "2381  Lunch time they have the $3.99 personal pan pi...        2.0   \n",
       "2382  This weekend I ordered delivery for the first ...        3.0   \n",
       "\n",
       "     review_count  \n",
       "2378           17  \n",
       "2379           17  \n",
       "2380           17  \n",
       "2381           17  \n",
       "2382           17  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1[['business_id','stars_x','state','text','stars_y','review_count']]\n",
    "df1=df1.rename(columns={'stars_x':'shop_star','stars_y':'user_star'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_star\n",
    "p3 = sns.countplot(x='user_star', data=df1) #so many 1.0 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_star</th>\n",
       "      <th>shop_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>So now for an update.\\n\\nI've ordered 3x from ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>I came here for an interview, I found out that...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>I know it's Pizza Hut, but even with my expect...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>Lunch time they have the $3.99 personal pan pi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>This weekend I ordered delivery for the first ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  \\\n",
       "2378  kqhHw_9KA30_RYk66mMbJA   \n",
       "2379  kqhHw_9KA30_RYk66mMbJA   \n",
       "2380  kqhHw_9KA30_RYk66mMbJA   \n",
       "2381  kqhHw_9KA30_RYk66mMbJA   \n",
       "2382  kqhHw_9KA30_RYk66mMbJA   \n",
       "\n",
       "                                                   text  user_star  shop_star  \n",
       "2378  So now for an update.\\n\\nI've ordered 3x from ...        1.0        1.0  \n",
       "2379  I came here for an interview, I found out that...        1.0        1.0  \n",
       "2380  I know it's Pizza Hut, but even with my expect...        1.0        1.0  \n",
       "2381  Lunch time they have the $3.99 personal pan pi...        2.0        1.0  \n",
       "2382  This weekend I ordered delivery for the first ...        3.0        1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df1[['business_id','text','user_star','shop_star']]\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "def text_preprocess(text):\n",
    "    text1 = [word for word in text if word not in string.punctuation] #punctuation\n",
    "    text1 = ''.join(text1)\n",
    "    \n",
    "    text2 = text1.split() #split\n",
    "    \n",
    "    stop_words = stopwords.words('english')     #stop_words\n",
    "    stop_words.extend(['pizza','good','food','great','one','get','back','would','really','also','got','u','love','ive','im',\n",
    "                      \"food\",\"drink\",\"eat\", \"now\", \"pizza\", \"flavor\", \"flavors\", \"Dominos\", \"Domino\", \"time\",\"told\",\"order\",\"ordered\",\"called\",\n",
    "                  \"store\", \"said\",\"one\",\"pizzas\",\"place\",\"give\",\"got\",\"call\",\"asked\",\"even\",\"really\",\"Hut\",\"say\",\"will\",\"still\",\"ready\",\n",
    "                 \"little\",\"Papa\",\"John\", \"Johns\",\"Caesars\",\"go\",\"Murphy\",\"Sbarro\",\"Marco\",\"Marcos\",\"E\",\"Chuck\",\"Cici\",\"always\",\n",
    "                 \"hour\",\"never\",\"first\",\"minute\",\"phone\",\"minutes\",\"back\",\"u\",\"come\",\"going\",\"us\",\"lot\",\"son\",\n",
    "                      \"hut\",'location', 'customer', 'dont', 'like', 'didnt','could', 'ever', 'online', \n",
    "                       'take', 'guy', 'delivered', 'waiting', 'took','way','half','day','cant',\n",
    "                    'came', 'ordering', 'tell', 'min', 'later','people','experience','person',\n",
    "                     'year','people', 'person','thing','hold','delivery', 'service', 'manager', 'driver', 'cold', 'cheese', \n",
    "                       'hour', 'time', 'crust', 'employee', 'wait', 'wrong', 'star', 'last', 'pick', 'horrible', \n",
    "                       'credit', 'money', 'rude', 'bad', 'number', 'terrible', 'sauce', \n",
    "                       'night', 'refund', 'hung', 'review', 'business', 'wasnt', 'someone',\n",
    "                       'hour', 'time', 'name', 'nothing', 'customer', 'employee', 'staff', 'restaurant', 'late', 'sure', 'min', 'box', 'order', 'card', 'work', 'door', 'extra', 'address', 'right', 'star', 'corporate', 'couldnt', \n",
    "                       'problem', 'something', 'pm', 'new', 'wont', 'ask', 'deliver', 'home'\n",
    "                       ])\n",
    "    #stop_words2 = stop_words\n",
    "    text3 = [word.lower() for word in text2 if word.lower() not in stop_words]   #lower\n",
    "    \n",
    "    wnl = WordNetLemmatizer()    #lemmatization\n",
    "    text4 = pos_tag([wnl.lemmatize(word) for word in text3])\n",
    "    text5 = [word for word,type0 in text4 if type0 in ['NN']] #just keep noun\n",
    "    return text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = text_preprocess('you are a cute pigs and dogs! hut, and far big small you are dogs good good good good good good')\n",
    "tem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = review.copy()\n",
    "df3['text_processed']= df3['text'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list)) / (1 + n_containing(word, count_list))\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)\n",
    "\n",
    "def count_term(text):\n",
    "    count = Counter(text)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat reviews #group by bussiness_id\n",
    "loop = df3[df3['user_star'] == 1]['text_processed'].count()\n",
    "b = df3[df3['user_star'] == 1]\n",
    "b.reset_index(drop=True, inplace=True)\n",
    "wordlist = []\n",
    "for i in range(0,loop-1): \n",
    "    for word in b['text_processed'][i]:\n",
    "        wordlist.append(word)\n",
    "text1 = wordlist\n",
    "review_staris1 = text1\n",
    "\n",
    "loop = df3[df3['user_star'] == 5]['text_processed'].count()\n",
    "b = df3[df3['user_star'] == 5]\n",
    "b.reset_index(drop=True, inplace=True)\n",
    "wordlist = []\n",
    "for i in range(0,loop-1): \n",
    "    for word in b['text_processed'][i]:\n",
    "        wordlist.append(word)\n",
    "text5 = wordlist\n",
    "review_staris5 = text5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text1,text5]\n",
    "countlist = []\n",
    "for text in texts:\n",
    "    countlist.append(count_term(text))\n",
    "for i, count in enumerate(countlist):\n",
    "    print(\"Top words in review_starIs {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "    sorted_words = sorted(scores.items(), key = lambda x: x[1], reverse=True)\n",
    "    word_list = []\n",
    "    for word, score in sorted_words[:10]:\n",
    "        #print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "        #print(\"\\\"{}\\\"\".format(word))\n",
    "        word_list.append(word)\n",
    "    print(word_list)  #top words in reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['delivery','pay','card','credit','pickup','smile',\n",
    "             'service','rude','polite','management','car','wait','refund','friendly','kind','manager','counter','staff','driver','employee',\n",
    "             'cheese','fresh','pepperoni','sauce','star','delicious','thin','garlic','stick','breadstick','pie','pepper','crispy',\n",
    "             'slice','email','pasta','wing','chicken','bread','steak','juice','yummy','mushroom','meat','marinara'\n",
    "             'family','brownie', 'bbq', 'water','bacon','cinnamon','sausage'\n",
    "            ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['delivery','service','rude','polite','management','car','wait','friendly','pepperoni',\n",
    "             'sauce','wing','chicken','bread','meat','family'\n",
    "            ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_demo = pd.DataFrame(columns=(['c', 'a']+['aa']))\n",
    "# df_demo.loc[df_demo.shape[0]] = dict(zip(df_demo.columns, ['dog',12,33]))\n",
    "# df_demo\n",
    "# ccc = 'cat'\n",
    "# [ccc]+[12,33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_demo = pd.DataFrame(columns=(['c', 'a']+['aa']))\n",
    "# df_demo.loc[0]=['cat', 3, 1]\n",
    "# df_demo.loc[2]=['cat1', 31, 1]\n",
    "# df_demo\n",
    "\n",
    "# df.loc[df.shape[0]] = dict(zip(df.columns, value))\n",
    "\n",
    "# a = a.append(pd.DataFrame(np.matrix(np.repeat(1, 11)),columns = a.columns))\n",
    "\n",
    "# wordlist\n",
    "# bussiness_list \n",
    "# bussiness_senti = 'bussi' + word_list\n",
    "# for b in buss_list:\n",
    "#     texttt = df3.text[df3.buss == b]\n",
    "#     word_pos_score\n",
    "#     v = [b] + word_pos_score\n",
    "#     bussiness_senti.loc[df.shape[0]] = dict(zip(df.columns, value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bussiness sentiment\n",
    "business_list = df3.business_id.unique()\n",
    "word_list = ['wing','cheese','pepperoni','bread'] \n",
    "business_sentiment_score = pd.DataFrame(columns=(['business_id'] + word_list))\n",
    "for b in business_list:\n",
    "    #compute word positive score\n",
    "    text0 = \"\".join(review for review in df3.text[df3.business_id == b]) \n",
    "    word_pos_score = []\n",
    "    for word in word_list:\n",
    "        review_set = [sentence + '.' for sentence in text0.split('.') if word in sentence]\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        sentciciDeli = 0\n",
    "        count = 0\n",
    "        total = 0\n",
    "        for sentence in  review_set:\n",
    "            count = count + 1\n",
    "            d = sia.polarity_scores(sentence)\n",
    "            value = d['compound']\n",
    "            total = total + value\n",
    "        if count != 0:\n",
    "            pos_score = float(total)/float(count)\n",
    "        else :\n",
    "            pos_score = None\n",
    "        word_pos_score.append(pos_score)\n",
    "    tem_busi_score = [b] + word_pos_score\n",
    "    business_sentiment_score.loc[business_sentiment_score.shape[0]] = dict(zip(business_sentiment_score.columns, tem_busi_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>wing</th>\n",
       "      <th>cheese</th>\n",
       "      <th>pepperoni</th>\n",
       "      <th>bread</th>\n",
       "      <th>shop_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kqhHw_9KA30_RYk66mMbJA</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30525</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hWRZaOk4JWUPFhcomdOLwA</td>\n",
       "      <td>-0.31415</td>\n",
       "      <td>-0.1657</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6EwA03Jcw5VaPc8BNiwrpw</td>\n",
       "      <td>0.109283</td>\n",
       "      <td>0.147008</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>HUEZLPIM64cDZnfHE1H3AA</td>\n",
       "      <td>0.00128667</td>\n",
       "      <td>0.33189</td>\n",
       "      <td>-0.24695</td>\n",
       "      <td>0.338888</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>_zy93iWV8Z-YmfvjWPcfAQ</td>\n",
       "      <td>0.0695571</td>\n",
       "      <td>-0.0878714</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id        wing     cheese pepperoni     bread  \\\n",
       "0    kqhHw_9KA30_RYk66mMbJA           0   -0.30525   -0.0516      None   \n",
       "19   hWRZaOk4JWUPFhcomdOLwA    -0.31415    -0.1657    0.6452    0.3555   \n",
       "48   6EwA03Jcw5VaPc8BNiwrpw    0.109283   0.147008         0   -0.0875   \n",
       "79   HUEZLPIM64cDZnfHE1H3AA  0.00128667    0.33189  -0.24695  0.338888   \n",
       "139  _zy93iWV8Z-YmfvjWPcfAQ   0.0695571 -0.0878714      None    0.1158   \n",
       "\n",
       "     shop_star  \n",
       "0          1.0  \n",
       "19         2.0  \n",
       "48         2.0  \n",
       "79         3.5  \n",
       "139        2.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_sentiment_score\n",
    "business_user_star = df3[['business_id','shop_star']]\n",
    "result = pd.merge(left = business_sentiment_score, right = business_user_star, how = 'inner', on = ['business_id'])\n",
    "result = result.drop_duplicates()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wing         0.072730\n",
       "cheese       0.025700\n",
       "pepperoni    0.091862\n",
       "bread        0.115951\n",
       "shop_star    2.065517\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('words_sentiment_compound.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.isnull().sum()/145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment\n",
    "text0 = \"\".join(review for review in df3.text[df3.user_star == 1])  #df3.text[df3.user_star == 1]\n",
    "word_pos_score = []\n",
    "for word in word_list:\n",
    "    review_set = [sentence + '.' for sentence in text0.split('.') if word in sentence]\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentciciDeli = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for sentence in  review_set:\n",
    "        count = count +1;\n",
    "        d = sia.polarity_scores(sentence)\n",
    "        value = d['pos']\n",
    "        total = total + value;\n",
    "    pos_score = float(total)/float(count)\n",
    "    word_pos_score.append(pos_score) \n",
    "\n",
    "#merge word_list and word_pos_score\n",
    "# print(word_list)\n",
    "# print(word_pos_score)\n",
    "word_sentiment = pd.concat([pd.DataFrame(word_list),pd.DataFrame(word_pos_score)], axis=1)\n",
    "word_sentiment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment\n",
    "text0 = \"\".join(review for review in df3.text[df3.user_star == 5])  \n",
    "word_pos_score = []\n",
    "for word in word_list:\n",
    "    review_set = [sentence + '.' for sentence in text0.split('.') if word in sentence]\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentciciDeli = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for sentence in  review_set:\n",
    "        count = count +1;\n",
    "        d = sia.polarity_scores(sentence)\n",
    "        value = d['pos']\n",
    "        total = total + value;\n",
    "    pos_score = float(total)/float(count)\n",
    "    word_pos_score.append(pos_score) \n",
    "\n",
    "#merge word_list and word_pos_score\n",
    "# print(word_list)\n",
    "# print(word_pos_score)\n",
    "word_sentiment = pd.concat([pd.DataFrame(word_list),pd.DataFrame(word_pos_score)], axis=1)\n",
    "word_sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
